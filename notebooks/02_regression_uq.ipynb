{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Uncertainty estimation for regression\n",
    "We would demonstrate how to estimate the uncertainty for a regression task. In this case we treat uncertainty as a standard deviation for test data points.\n",
    "As an example dataset we take the kinemtic movement data from UCI database and would estimate the uncertainty prediction with log likelihood metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "import alpaca.utils.datasets.config as alpaca_config\n",
    "alpaca_config.DATA_DIR = './datasets/alpaca_datasets'\n",
    "from alpaca.ue import MCDUE\n",
    "from alpaca.utils.datasets.builder import build_dataset\n",
    "from alpaca.utils.ue_metrics import ndcg, uq_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "The alpaca library has a few regression dataset provided (these datasets often used in the related scientific papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset('kin8nm', val_split=1_000)\n",
    "x_train, y_train = dataset.dataset('train')\n",
    "x_val, y_val = dataset.dataset('val')\n",
    "x_train.shape, y_val.shape\n",
    "train_ds = TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "val_ds = TensorDataset(torch.FloatTensor(x_val), torch.FloatTensor(y_val))\n",
    "train_loader = DataLoader(train_ds, batch_size=512)\n",
    "val_loader = DataLoader(val_ds, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the simple model\n",
    "We'll replace common nn.Dropout layer with ann.Dropout from alpaca.\n",
    "Alpaca version allow to switch on the dropout during inference without worrying other \"training\" layers, like batch norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, base_size=64, dropout_rate=0., dropout_mask=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 4*base_size),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(4*base_size, 2*base_size),\n",
    "            nn.Dropout(dropout_rate, dropout_mask),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(2*base_size, 1*base_size),\n",
    "            nn.Dropout(dropout_rate, dropout_mask),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(base_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = MLP(input_size=8, dropout_rate=0.1, dropout_mask=BasicBernoulliMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss on last batch 0.008341232314705849\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model.train()\n",
    "for epochs in range(100):\n",
    "    for x_batch, y_batch in train_loader: # Train for one epoch\n",
    "        predictions = model(x_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print('Train loss on last batch', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.8792046616990106\n"
     ]
    }
   ],
   "source": [
    "# Check model effectiveness \n",
    "model.eval()\n",
    "x_batch, y_batch = next(iter(val_loader))\n",
    "predictions = model(x_batch).detach().cpu().numpy()\n",
    "print('R2:', r2_score(predictions, y_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate uncertainty\n",
    "We compare the log likelihood for constant prediction and monte-carlo uncertainty estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncertainty estimation with MCDUE_regression approach:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncertainty estimation with MCDUE_regression approach: 100%|██████████| 25/25 [00:00<00:00, 1427.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate uncertainty estimation\n",
    "estimator = MCDUE(model)\n",
    "predictions, estimations = estimator(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score for const std is  1.2691531\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "const_std = np.std(y_val)\n",
    "errors = np.abs(predictions - y_batch.reshape((-1)).numpy())\n",
    "score = uq_ll(errors, np.ones_like(errors) * const_std)\n",
    "print(\"Quality score for const std is \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "estimator = MCDUE(model, nn_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncertainty estimation with MCDUE_regression approach:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncertainty estimation with MCDUE_regression approach: 100%|██████████| 100/100 [00:00<00:00, 1150.92it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, estimations = estimator(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score for monte-carlo dropout is  0.3688784\n"
     ]
    }
   ],
   "source": [
    "errors = np.abs(predictions - y_batch.reshape((-1)).numpy())\n",
    "score = uq_ll(np.array(errors), predictions)\n",
    "print(\"Quality score for monte-carlo dropout is \", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Gal Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mc_regression(X_pool: torch.Tensor, model, n_runs):   \n",
    "    mcd_runs = None\n",
    "    model = model.train()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for nn_run in tqdm(range(n_runs)):\n",
    "            prediction = model(X_pool)\n",
    "            mcd_runs = (\n",
    "                prediction.flatten().cpu()[None, ...]\n",
    "                if mcd_runs is None\n",
    "                else torch.cat(\n",
    "                    [mcd_runs, prediction.flatten().cpu()[None, ...]], dim=0\n",
    "                )\n",
    "            )\n",
    "\n",
    "    predictions = mcd_runs.mean(dim=0)\n",
    "    uncertainty = mcd_runs.std(dim=0)\n",
    "\n",
    "    return predictions, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 946.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1251.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score for monte-carlo dropout is  -1.6109062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "scoring = nn.GaussianNLLLoss(reduction='none')\n",
    "\n",
    "scoring_list = []\n",
    "\n",
    "for x_batch, y_batch in val_loader:\n",
    "\n",
    "    predictions, uq = do_mc_regression(x_batch, model, n_runs=100)\n",
    "\n",
    "\n",
    "    \n",
    "    score = scoring(predictions, y_batch.flatten(), torch.square(uq))\n",
    "    scoring_list.append(score.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "cat_scores = np.concatenate(scoring_list)\n",
    "score = np.mean(cat_scores)\n",
    "print(\"Quality score for monte-carlo dropout with gaussian NLLLoss is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(scoring_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
